{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc57bd08",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d18d286c",
   "metadata": {},
   "source": [
    "# An End-to-end Example using PyTorch Geometric on IPUs\n",
    "\n",
    "Graph Neural Networks (GNNs) are models designed to derive insights from unstructured data that can be represented as graphs. \n",
    "They are used to address a wide variety of scientific and industrial problems: their application to chemistry and biology has unlocked\n",
    "a new era of drug discovery, while their use to analyse product and customer interactions is improving recommender systems.\n",
    "\n",
    "GNNs are ideal to run on Graphcore IPUs, due to IPU architectural characteristics such as very large amounts of on-chip SRAM,\n",
    "which makes message passing operations typical of GNN workloads much faster than other processor types. For more details about why IPUs \n",
    "are extremely capable at running GNN workloads please check out our [blog post](https://www.graphcore.ai/posts/what-gnns-are-great-at-and-why-graphcore-ipus-are-great-at-gnns) on this topic. \n",
    "The advantages of running GNNs on IPUs compared to other processor types can be seen in our [benchmarks](../benchmarks).\n",
    "\n",
    "This tutorial will get you started training and running inference on your first GNN model on IPUs.\n",
    "We will go through the following steps required to run a PyTorch Geometric model on IPU, detailing the journey of running GNNs on the IPU:\n",
    " * Loading a PyTorch Geometric dataset\n",
    " * Using a [PopTorch Geometric](https://docs.graphcore.ai/projects/poptorch-geometric-user-guide/) dataloader to achieve fixed size outputs\n",
    " * Creating a model\n",
    " * Adjusting the model to satisfy PopTorch requirements\n",
    " * Start training on the IPU\n",
    " * Run inference on the IPU\n",
    "\n",
    "The specific task we will cover is to classify the nodes of the PyTorch Geometric [Cora citation network dataset](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid);\n",
    "\n",
    "While this tutorial will cover enough of the basics of GNNs, PyTorch Geometric and PopTorch\n",
    "for you to start developing and porting your GNN applications to the IPU;\n",
    "the following resources can be used to complement your understanding of:\n",
    "\n",
    "- PopTorch : [Introduction to PopTorch - running a simple model](https://github.com/graphcore/examples/tree/master/tutorials/tutorials/pytorch/basics);\n",
    "- GNNs : [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n",
    "- PyTorch Geometric (PyG): [Official notebooks examples and tutorials](https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d31f153",
   "metadata": {},
   "source": [
    "## Running on Paperspace\n",
    "\n",
    "The Paperspace environment lets you run this notebook with no set up. To improve your experience we preload datasets and pre-install packages, this can take a few minutes, if you experience errors immediately after starting a session please try restarting the kernel before contacting support. If a problem persists or you want to give us feedback on the content of this notebook, please reach out to through our community of developers using our [slack channel](https://www.graphcore.ai/join-community) or raise a [GitHub issue](https://github.com/graphcore/examples).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Python packages installed with `pip install -r ../requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r ../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac5f93ad",
   "metadata": {},
   "source": [
    "And for compatibility with the Paperspace environment variables we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "executable_cache_dir = (\n",
    "    os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\")\n",
    "    + \"/pyg-a-worked-example\"\n",
    ")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7455515c",
   "metadata": {},
   "source": [
    "Now we are ready to start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dba776b9",
   "metadata": {},
   "source": [
    "## Loading a PyTorch Geometric dataset\n",
    "\n",
    "PyTorch Geometric provides simple access to many of the datasets used in literature for GNNs.\n",
    "The full list of datasets is available in the [project's documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch-geometric-datasets).\n",
    "\n",
    "For this tutorial we will use the `Cora` citation network dataset within the `Planetoid` benchmark suite to train our first GNN and run it on the IPU for the task of node classification.\n",
    "The `Cora` dataset features a single graph where nodes represent documents and edges represent citation links. Let's load the dataset and take a look at some of its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.AddSelfLoops()])\n",
    "\n",
    "dataset = Planetoid(root=dataset_directory, name=\"Cora\", transform=transform)\n",
    "data = dataset[0]  # Access the citation graph as Data object\n",
    "\n",
    "print(f\"Dataset: {dataset}: \")\n",
    "print(f\"Number of graphs: {len(dataset)}: \")\n",
    "print(f\"Number of features: {dataset.num_features}: \")\n",
    "print(f\"Number of classes: {dataset.num_classes}: \")\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(f\"{data.num_nodes = }\")\n",
    "print(f\"{data.num_edges = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cfff1ac",
   "metadata": {},
   "source": [
    "Graphs in PyTorch Geometric are stored in `Data` objects which provide an expressive string representation (see above), and a neat interface for accessing properties of the graph, for example its number of nodes and edges.\n",
    "The `edge_index` property describes the graph connectivity, while `x` represents the node features (1433-dim feature vector for each node) and `y` represents the node labels (each node is associated to one class).\n",
    "It's also worth noting the mask properties which denotes against which nodes to train/validate/test as we already know their community assignment. \n",
    "PyTorch Geometric datasets support transforms for pre-processing datasets on CPU before passing them to the model. In addition to using transforms for data augmentation they can also be useful to apply data processing which does not have learnable parameters and is not supported on the IPU.\n",
    "\n",
    "You may notice that in the code block above we made use of two transforms:\n",
    "- `NormalizeFeatures()` to row-normalize the input feature vector;\n",
    "- `AddSelfLoops()` to add self-loops to the dataset. Self-loops are edges which connect a node to itself and facilitate the communication of the node's feature across layers. Implementing self-loops corresponds to filling in the diagonal of the adjacency matrix.\n",
    "\n",
    "Now we have the dataset loaded we can use a dataloader to efficiently load our data onto the IPU, in the next section we will see how to do that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3b5f3f",
   "metadata": {},
   "source": [
    "## Using a dataloader\n",
    "\n",
    "There are a number of reasons why you may want to use a dataloader to load your dataset into your model. When you are using IPUs, the main reasons to use a dataloader are:\n",
    " * to achieve the most efficient loading performance;\n",
    " * to enable using particular PopTorch features such as replication and gradient accumulation;\n",
    " * to achieve fixed size batches required for the IPU.\n",
    "\n",
    "[PopTorch Geometric](https://docs.graphcore.ai/projects/poptorch-geometric-user-guide/), the IPU-specific PyTorch Geometric library, provides a wrapper for the PopTorch dataloader, making it easy to get performant PyTorch Geometric models running on the IPU. As we only have a single item in our dataset we do not need to worry about making our batches fixed size so we can use the most basic of PopTorch Geometric's dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a13411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poptorch_geometric.dataloader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dd9dab5",
   "metadata": {},
   "source": [
    "Our dataloader is now ready to go. Let's move on to creating a model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76f0528b",
   "metadata": {},
   "source": [
    "## Creating a model\n",
    "\n",
    "Let's remind ourselves of the task to inform the model we want to create. We want to classify the nodes of the Cora citation network dataset. Let's take a look at some important GNN features to help us construct our model.\n",
    "\n",
    "### Message passing layers in PyTorch Geometric\n",
    "\n",
    "GNNs rely on message passing schemes to perform neighbourhood aggregation of node and edge features, explained in more detail in [PyTorch Geometric white paper](https://arxiv.org/abs/1903.02428).\n",
    "This scheme aggregates features along the structure of the graph and it calculates updated feature vectors for each node and edge.\n",
    "MLP Layers with learnable parameters can be introduced in the calculation:\n",
    "\n",
    "- During the message passing: features of a neighbouring node and a connecting edge may be processed through a dense layer to calculate a message;\n",
    "- After aggregation: the combined messages are processed through neural layers to learn new derived features.\n",
    "\n",
    "An important property of neighbourhood aggregation schemes is that they are \"permutation invariant\": the order in which nodes or edges appear in the arrays does not affect them.\n",
    "\n",
    "PyTorch Geometric offers a large number of message passing layers which aggregate node and edge features. The full list is available in the [convolutional layers](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers) section of the PyTorch Geometric documentation.\n",
    "\n",
    "Let's take a look at the support convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import nn\n",
    "\n",
    "# List all the layers which are a subclass of the MessagePassing layer\n",
    "attrs = []\n",
    "for attr in dir(nn):\n",
    "    try:\n",
    "        if issubclass(getattr(nn, attr), nn.MessagePassing):\n",
    "            attrs.append(attr)\n",
    "    except:\n",
    "        pass\n",
    "print(attrs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffcbbd51",
   "metadata": {},
   "source": [
    "For our task, a simple `GCNConv` layer will suffice. As we have added the self-loops to the dataset as a transform we can turn them off in the layer. Turning off the self-loops in the layer is also a change we must make to ensure our compiled graph for the IPU is static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "conv = GCNConv(16, 16, add_self_loops=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ed73cd0",
   "metadata": {},
   "source": [
    "Now we know about message passing, let's construct a model with these layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7f47492",
   "metadata": {},
   "source": [
    "### Using the GCNConv layer in a model\n",
    "\n",
    "We are now ready to write a small GNN model to process the Cora dataset using the `GCNConv` layer provided by PyTorch Geometric. We do this in the normal way with two small changes:\n",
    " * PopTorch requires the loss function to be part of the model, so we will move that in to the end of the forward pass.\n",
    " * Set the labels of the masked nodes to `-100` so they are ignored in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 16, add_self_loops=False)\n",
    "        self.conv2 = GCNConv(16, out_channels, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None, train_mask=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        if self.training:\n",
    "            y = torch.where(train_mask, y, -100)\n",
    "            loss = F.nll_loss(x, y)\n",
    "            return x, loss\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3302d06",
   "metadata": {},
   "source": [
    "The number of in channels for our model is the size of the input features. The number of out channels is the number of classes in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e91c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{dataset.num_node_features = }\")\n",
    "print(f\"{dataset.num_classes = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3a57493",
   "metadata": {},
   "source": [
    "Now we have described our model, let's initialise it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7aca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = dataset.num_node_features\n",
    "out_channels = dataset.num_classes\n",
    "\n",
    "model = GCN(in_channels, out_channels)\n",
    "model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e46137b2",
   "metadata": {},
   "source": [
    "Our model is ready for training, we will learn how to do that in the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8f59bd",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "We are now in the position to begin training our model. To make this model ready for training on the IPU we will wrap the model in PopTorch functionality. We do the following:\n",
    " * Use a PopTorch optimizer for better speed and memory performance on the IPU. `Adam` is a suitable optimizer for our task, so we can create the optimizer in the typical way.\n",
    " * Wrap the model in `poptorch.trainingModel`;\n",
    " * Use PopTorch options to make use of PopTorch and IPU features, here we only set a directory to save and load our compiled executable from. Take a look at the [PopTorch documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html?highlight=options#poptorch.Options) for some of the other features you could use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffeae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch\n",
    "\n",
    "optimizer = poptorch.optim.Adam(model.parameters(), lr=0.001)\n",
    "poptorch_options = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "poptorch_model = poptorch.trainingModel(model, poptorch_options, optimizer=optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79afb70a",
   "metadata": {},
   "source": [
    "We can then set up the training loop in a familiar way. The key things to note is, because we moved the loss function inside the model, we do not need to define the loss calculation, the backward pass or the optimizer step. PopTorch handles this all for us.\n",
    "\n",
    "Let's set up the training loop and run some epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    bar = tqdm(dataloader)\n",
    "    for data in bar:\n",
    "        _, loss = poptorch_model(\n",
    "            data.x, data.edge_index, y=data.y, train_mask=data.train_mask\n",
    "        )\n",
    "        bar.set_description(f\"Epoch {epoch} loss: {loss:0.6f}\")\n",
    "        losses.append(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0f64d8b",
   "metadata": {},
   "source": [
    "Our loss is decreasing nicely! We can now detach our training model from the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e03ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poptorch_model.detachFromDevice()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6dc3251",
   "metadata": {},
   "source": [
    "And let's visualise the loss per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd08bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(range(len(losses))), losses)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bc7e0bb",
   "metadata": {},
   "source": [
    "Looks like our model hasn't converged yet, feel free to increase the number of epochs and attempt to reach full convergence.\n",
    "\n",
    "Now we have trained the model, let's see how it does on our validation and test sets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7983a36",
   "metadata": {},
   "source": [
    "## Running inference on the trained model\n",
    "\n",
    "Once training is complete, it is typical to test its performance on the validation and test datasets, we will see how to do that in this section.\n",
    "\n",
    "For inference, we wrap set the model to evaluation mode and wrap in `poptorch.inferenceModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a364866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "poptorch_inf_model = poptorch.inferenceModel(model, options=poptorch_options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8379ac8f",
   "metadata": {},
   "source": [
    "We can use this model in inference as normal. In the following we get the single large graph of data and feed it into the inference model, get the result, finally detaching our model from the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataset))\n",
    "logits = poptorch_inf_model(data.x, data.edge_index)\n",
    "poptorch_inf_model.detachFromDevice()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7142b4a8",
   "metadata": {},
   "source": [
    "We get the logits back with which we can calculate the accuracy of our model. First we will convert our logits to predictions. As this is a classification task with 7 possible classes, we find the position where the logits are the largest, this is the predicted class for that particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da46226",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logits.argmax(dim=1)\n",
    "pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd47b128",
   "metadata": {},
   "source": [
    "Now we can calculate how many of these predictions are correct. We use `val_mask` for this to ensure we are only taking the accuracy of the nodes we care about, the ones in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720eed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_results = pred[data.val_mask] == data.y[data.val_mask]\n",
    "accuracy = int(correct_results.sum()) / int(data.val_mask.sum())\n",
    "print(f\"Validation accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5037034a",
   "metadata": {},
   "source": [
    "And we do the same with the test dataset, using the `test_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d880db",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_results = pred[data.test_mask] == data.y[data.test_mask]\n",
    "accuracy = int(correct_results.sum()) / int(data.test_mask.sum())\n",
    "print(f\"Test accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4236e29",
   "metadata": {},
   "source": [
    "Here we did the accuracy calculation on the CPU. We could equally have placed the functionality in our model and let the IPU do the work. Why not try to make a change to return the accuracy from the IPU instead of calculating on the CPU?\n",
    "\n",
    "As our model hadn't fully converged our accuracy could be improved. Try adjusting the hyperparameters using the validation accuracy and see what test accuracy you can achieve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85825e71",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we saw an end to end example of running a GNN on IPUs for a particular task.\n",
    "\n",
    "We built a simple GNN model based on the the `GCNConv` layer provided by the PyTorch Geometric library, trained it with PopTorch and predicted the `Cora` dataset node features.\n",
    "\n",
    "A more in-depth overview of the data handling techniques needed for other types of graph problems can be found in the following links:\n",
    "\n",
    "- If you are interested in \"small graph\" problems of the type found in healthcare and chemistry, we recommend you check out the tutorials 3 and 4 on [Small Graph Batching with Padding](../3_small_graph_batching_with_padding/3_small_graph_batching_with_padding.ipynb) and [Small Graph Batching with Packing](../4_small_graph_batching_with_packing/4_small_graph_batching_with_packing.ipynb).\n",
    "- If you are looking to apply GNNs to larger graphs, similar to those found in online advertising, shopping and social networks, we recommend you to jump to our [Cluster CGN example](../../../../gnn/cluster_gcn/pytorch_geometric/node_classification_with_cluster_gcn.ipynb), which showcases how to train it for node classification using sampling. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
