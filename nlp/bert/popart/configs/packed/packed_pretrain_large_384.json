{
    "task": "PRETRAINING",
    "use_packed_sequence_format": true,
    "max_sequences_per_pack": 3,
    "num_layers": 24,
    "encoder_start_ipu": 0,
    "layers_per_ipu": [3, 7, 7, 7],
    "hidden_size": 1024,
    "attention_heads": 16,
    "sequence_length": 384,
    "mask_tokens": 56,
    "vocab_length": 30400,
    "popart_dtype": "FLOAT16",
    "no_dropout": false,
    "no_attn_dropout": true,
    "stochastic_rounding": true,
    "enable_half_partials": true,
    "device_iterations":  1,
    "training_steps": 2137,
    "steps_per_log": 100,
    "aggregate_metrics_over_steps": 1,
    "loss_scaling": 64.0,
    "micro_batch_size": 2,
    "global_batch_size": 9600,
    "replication_factor": 4,
    "split_qkv": true,
    "optimizer_state_offchip": true,
    "replicated_tensor_sharding": true,
    "gradient_reduction_type": "Mean",
    "optimizer": "LAMB_NO_BIAS",
    "beta1": 0.9,
    "beta2": 0.999,
    "weight_decay": 1e-2,
    "learning_rate_function": "Linear",
    "learning_rate": 0.002828427125,
    "lr_warmup_steps": 274,
    "lr_steps_per_decay_update": 8,
    "shuffle": true,
    "duplication_factor": 1,
    "epochs_to_cache": 0,
    "embedding_serialization_vocab_steps": 5,
    "available_memory_proportion": [0.15, 0.4, 0.4, 0.4],
    "pipeline": true,
    "checkpoint_dir": "checkpoints/packed/packed_pretrain_large_384",
    "no_validation": true
}
