{
    "task": "PRETRAINING",
    "num_layers": 12,
    "layers_per_ipu": 1,
    "hidden_size": 768,
    "attention_heads": 12,
    "sequence_length": 384,
    "mask_tokens": 56,
    "popart_dtype": "FLOAT16",
    "no_dropout": true,
    "learning_rate": 0.0004,
    "lr_schedule_by_step": {
        "0": 0.0004,
        "512": 0.00038,
        "1024": 0.000361,
        "1536": 0.00034295,
        "2048": 0.000325803,
        "2560": 0.000309512,
        "3072": 0.000294037,
        "3584": 0.000279335,
        "4096": 0.000265368,
        "4608": 0.0002521,
        "5120": 0.000239495,
        "5632": 0.00022752,
        "6144": 0.000216144,
        "6656": 0.000205337,
        "7168": 0.00019507,
        "7680": 0.000185316,
        "8192": 0.000176051,
        "8704": 0.000167248,
        "9216": 0.000158886,
        "9728": 0.000150941,
        "10240": 0.000143394,
        "10752": 0.000136225,
        "11264": 0.000129413,
        "11776": 0.000122943,
        "12288": 0.000116796,
        "12800": 0.000110956,
        "13312": 0.000105408,
        "13824": 0.000100138,
        "14336": 9.51308e-05,
        "14848": 9.03742e-05,
        "15360": 8.58555e-05,
        "15872": 8.15627e-05,
        "16384": 7.74846e-05,
        "16896": 7.36104e-05,
        "17408": 6.99298e-05,
        "17920": 6.64334e-05,
        "18432": 6.31117e-05,
        "18944": 5.99561e-05,
        "19456": 5.69583e-05,
        "19968": 5.41104e-05,
        "20480": 5.14049e-05,
        "20992": 4.88346e-05
    },
    "loss_scaling": 20.0,
    "momentum": 0.984375,
    "pipeline_lr_scaling": true,
    "pipeline_lr_scaling_offset": 0.25,
    "pipeline_momentum_scaling": true,
    "pipeline_momentum_scaling_offset": 0.1,
    "stochastic_rounding": true,
    "no_outlining": true,
    "custom_ops": [
        "gather",
        "attention"
    ],
    "batches_per_step": 8192,
    "epochs": 6,
    "epochs_per_save": 1,
    "steps_per_save": 512,
    "steps_per_log": 100,
    "aggregate_metrics_over_steps": 1,
    "input_files": [
        "data/wikipedia/AA/sequence_384/wiki_00_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_01_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_02_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_03_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_04_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_05_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_06_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_07_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_08_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_09_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_10_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_11_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_12_tokenised",
        "data/wikipedia/AA/sequence_384/wiki_13_tokenised"
    ],
    "duplication_factor": 6,
    "epochs_to_cache": 3,
    "vocab_length": 30400,
    "projection_serialization_steps": 5,
    "split_linear_layers": true,
    "engine_cache": "__pretrain_base_384",
    "vocab_file": "data/ckpts/uncased_L-12_H-768_A-12/vocab.txt",
    "shuffle": true,
    "pipeline": true,
    "checkpoint_dir": "checkpoints/pretrain_base_384",
    "no_validation": true
}
